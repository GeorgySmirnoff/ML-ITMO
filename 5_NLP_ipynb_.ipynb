{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_NLP.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHX9p5jfTySS"
      },
      "source": [
        "## Задание 5.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EnHNZtbXlH0"
      },
      "source": [
        "Набор данных тут: https://github.com/sismetanin/rureviews, также есть в папке [Data](https://drive.google.com/drive/folders/1YAMe7MiTxA-RSSd8Ex2p-L0Dspe6Gs4L). Те, кто предпочитает работать с английским языком, могут использовать набор данных `sms_spam`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJox-LoonoPx"
      },
      "source": [
        "Применим полученные навыки и решим задачу анализа тональности отзывов. \n",
        "\n",
        "Нужно повторить весь пайплайн от сырых текстов до получения обученной модели.\n",
        "\n",
        "Обязательные шаги предобработки:\n",
        "1. токенизация\n",
        "2. приведение к нижнему регистру\n",
        "3. удаление стоп-слов\n",
        "4. лемматизация\n",
        "5. векторизация (с настройкой гиперпараметров)\n",
        "6. построение модели\n",
        "7. оценка качества модели\n",
        "\n",
        "Обязательно использование векторайзеров:\n",
        "1. мешок n-грамм (диапазон для n подбирайте самостоятельно, запрещено использовать только униграммы).\n",
        "2. tf-idf ((диапазон для n подбирайте самостоятельно, также нужно подбирать параметры max_df, min_df, max_features)\n",
        "3. символьные n-граммы (диапазон для n подбирайте самостоятельно)\n",
        "\n",
        "В качестве классификатора нужно использовать наивный байесовский классификатор. \n",
        "\n",
        "Для сравнения векторайзеров между собой используйте precision, recall, f1-score и accuracy. Для этого сформируйте датафрейм, в котором в строках будут разные векторайзеры, а в столбцах разные метрики качества, а в  ячейках будут значения этих метрик для соответсвующих векторайзеров."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_8YVx6dZe-g"
      },
      "source": [
        "%%capture\n",
        "!wget https://www.dropbox.com/s/2yms4xgtuvex3gx/women-clothing-accessories.csv\n",
        "!pip install pymorphy2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import *\n",
        "import re\n",
        "data = pd.read_csv(\"women-clothing-accessories.csv\", sep='\\t')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTNJ8CRhZhRk"
      },
      "source": [
        "analyzer = MorphAnalyzer()\n",
        "\n",
        "def bayes(vectorizer, vectorizer_x_train):\n",
        "  clf = MultinomialNB()\n",
        "  clf.fit(vectorizer_x_train, y_train)  \n",
        "  vectorizer_x_test = vectorizer.transform(X_test)\n",
        "  pred = clf.predict(vectorizer_x_test)\n",
        "  return classification_report(y_test, pred, output_dict=True), vectorizer, pred\n",
        "\n",
        "def processing(data):\n",
        "  sentences = []\n",
        "  for sentence in data:\n",
        "    sentence = sentence.lower()\n",
        "    for ch in string.punctuation:\n",
        "      sentence = sentence.replace(ch,\"\")\n",
        "    sentence = re.sub(r'\\d', '', sentence)\n",
        "    words = word_tokenize(sentence)\n",
        "    for i in range(len(words)):\n",
        "      words[i] = analyzer.parse(words[i])[0].normal_form\n",
        "    sentences.append(\" \".join(words))\n",
        "  return sentences\n",
        "\n",
        "data.review = processing(data.review)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.review, data.sentiment, train_size = 0.7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gb8duN4Zku3"
      },
      "source": [
        "vectorized_info = []\n",
        "\n",
        "for i in range(1, 7):#(1,6)\n",
        "  for j in range(i + 1, 10):#(i+1,6)\n",
        "    vectorizer = CountVectorizer(ngram_range=(i,j), analyzer=\"word\", stop_words=stopwords.words(\"russian\"))\n",
        "    vectorizer_x_train = vectorizer.fit_transform(X_train)\n",
        "    a = bayes(vectorizer, vectorizer_x_train)\n",
        "    vectorized_info.append([a, str(vectorizer)])\n",
        "\n",
        "\n",
        "for i in range(5, 12):#(3,6)\n",
        "  for j in range(i + 1, 6):#(i + 1,6)\n",
        "    vectorizer = CountVectorizer(ngram_range=(i,j), analyzer=\"char\", stop_words=stopwords.words(\"russian\"))\n",
        "    vectorizer_x_train = vectorizer.fit_transform(X_train)\n",
        "    a = bayes(vectorizer, vectorizer_x_train)\n",
        "    vectorized_info.append([a, str(vectorizer)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#В бустинге - градиент в пространстве модолей"
      ],
      "metadata": {
        "id": "oQIEua4Tt88b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALmtrEecZodf"
      },
      "source": [
        "for i in range(1, 4):\n",
        "  for j in range(i + 1, 4):\n",
        "    for max_df in [0.2, 0.4, 0.6]:#0.7/1.0/0.1\n",
        "      for min_df in [0.01, 0.02]:\n",
        "        for max_features in [2000, 4000, 8000]:\n",
        "          vectorizer = TfidfVectorizer(ngram_range=(i,j), max_df=max_df, min_df=min_df, max_features=max_features)\n",
        "          vectorizer_x_train = vectorizer.fit_transform(X_train)\n",
        "          a = bayes(vectorizer, vectorizer_x_train)\n",
        "          vectorized_info.append([a, str(vectorizer)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "_cGEsv52ZqU8",
        "outputId": "ab2f2e2a-9b48-43ae-ab34-912cc8483f32"
      },
      "source": [
        "results = []\n",
        "pattern = re.compile(r\"[a-zA-Z]+Vectorizer|'word'|'char'|\\([0-9,]+,[ 0-9]+\\)|min_df=[0-9.]|max_df=[0-9.]+|features=[0-9]+\")\n",
        "for vector_info in vectorized_info:\n",
        "  metrics = vector_info[0][0]['weighted avg']\n",
        "  parameters = pattern.findall(vector_info[1])\n",
        "  results.append({\"Vectorizer\": parameters[0], \"Parameters\": parameters[1:], \"Precision\": metrics[\"precision\"], \"Recall\": metrics[\"recall\"], \"F1-Score\": metrics['f1-score'], \"Accuracy\": vector_info[0][0]['accuracy']})\n",
        "data_result = pd.DataFrame(results)\n",
        "data_result.sort_values(by=[\"Accuracy\"], ascending=False).head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Parameters</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>[(1, 2)]</td>\n",
              "      <td>0.711296</td>\n",
              "      <td>0.708455</td>\n",
              "      <td>0.708764</td>\n",
              "      <td>0.708455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>['char', (4, 5)]</td>\n",
              "      <td>0.717458</td>\n",
              "      <td>0.705863</td>\n",
              "      <td>0.707919</td>\n",
              "      <td>0.705863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>[(1, 3)]</td>\n",
              "      <td>0.707111</td>\n",
              "      <td>0.705826</td>\n",
              "      <td>0.705839</td>\n",
              "      <td>0.705826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>[(1, 4)]</td>\n",
              "      <td>0.706199</td>\n",
              "      <td>0.705270</td>\n",
              "      <td>0.705242</td>\n",
              "      <td>0.705270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>[(1, 5)]</td>\n",
              "      <td>0.705937</td>\n",
              "      <td>0.705159</td>\n",
              "      <td>0.705111</td>\n",
              "      <td>0.705159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>['char', (3, 5)]</td>\n",
              "      <td>0.715690</td>\n",
              "      <td>0.703122</td>\n",
              "      <td>0.705388</td>\n",
              "      <td>0.703122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>CountVectorizer</td>\n",
              "      <td>['char', (3, 4)]</td>\n",
              "      <td>0.707426</td>\n",
              "      <td>0.694604</td>\n",
              "      <td>0.696891</td>\n",
              "      <td>0.694604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>[max_df=0.6, features=2000, min_df=0, (1, 2)]</td>\n",
              "      <td>0.689568</td>\n",
              "      <td>0.675568</td>\n",
              "      <td>0.678225</td>\n",
              "      <td>0.675568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>[max_df=0.6, features=8000, min_df=0, (1, 2)]</td>\n",
              "      <td>0.689568</td>\n",
              "      <td>0.675568</td>\n",
              "      <td>0.678225</td>\n",
              "      <td>0.675568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>[max_df=0.6, features=4000, min_df=0, (1, 2)]</td>\n",
              "      <td>0.689568</td>\n",
              "      <td>0.675568</td>\n",
              "      <td>0.678225</td>\n",
              "      <td>0.675568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>[max_df=0.6, features=2000, min_df=0, (1, 3)]</td>\n",
              "      <td>0.689826</td>\n",
              "      <td>0.674716</td>\n",
              "      <td>0.677199</td>\n",
              "      <td>0.674716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>[max_df=0.6, features=4000, min_df=0, (1, 3)]</td>\n",
              "      <td>0.689826</td>\n",
              "      <td>0.674716</td>\n",
              "      <td>0.677199</td>\n",
              "      <td>0.674716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>[max_df=0.6, features=8000, min_df=0, (1, 3)]</td>\n",
              "      <td>0.689826</td>\n",
              "      <td>0.674716</td>\n",
              "      <td>0.677199</td>\n",
              "      <td>0.674716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>[max_df=0.4, features=8000, min_df=0, (1, 3)]</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>0.674308</td>\n",
              "      <td>0.676664</td>\n",
              "      <td>0.674308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>[max_df=0.4, features=4000, min_df=0, (1, 3)]</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>0.674308</td>\n",
              "      <td>0.676664</td>\n",
              "      <td>0.674308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>[max_df=0.4, features=2000, min_df=0, (1, 3)]</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>0.674308</td>\n",
              "      <td>0.676664</td>\n",
              "      <td>0.674308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>[max_df=0.2, features=2000, min_df=0, (1, 2)]</td>\n",
              "      <td>0.688978</td>\n",
              "      <td>0.674271</td>\n",
              "      <td>0.676901</td>\n",
              "      <td>0.674271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>[max_df=0.2, features=4000, min_df=0, (1, 2)]</td>\n",
              "      <td>0.688978</td>\n",
              "      <td>0.674271</td>\n",
              "      <td>0.676901</td>\n",
              "      <td>0.674271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>[max_df=0.2, features=8000, min_df=0, (1, 2)]</td>\n",
              "      <td>0.688978</td>\n",
              "      <td>0.674271</td>\n",
              "      <td>0.676901</td>\n",
              "      <td>0.674271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>TfidfVectorizer</td>\n",
              "      <td>[max_df=0.2, features=4000, min_df=0, (1, 3)]</td>\n",
              "      <td>0.689747</td>\n",
              "      <td>0.674197</td>\n",
              "      <td>0.676599</td>\n",
              "      <td>0.674197</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Vectorizer  ...  Accuracy\n",
              "0   CountVectorizer  ...  0.708455\n",
              "12  CountVectorizer  ...  0.705863\n",
              "1   CountVectorizer  ...  0.705826\n",
              "2   CountVectorizer  ...  0.705270\n",
              "3   CountVectorizer  ...  0.705159\n",
              "11  CountVectorizer  ...  0.703122\n",
              "10  CountVectorizer  ...  0.694604\n",
              "25  TfidfVectorizer  ...  0.675568\n",
              "27  TfidfVectorizer  ...  0.675568\n",
              "26  TfidfVectorizer  ...  0.675568\n",
              "43  TfidfVectorizer  ...  0.674716\n",
              "44  TfidfVectorizer  ...  0.674716\n",
              "45  TfidfVectorizer  ...  0.674716\n",
              "39  TfidfVectorizer  ...  0.674308\n",
              "38  TfidfVectorizer  ...  0.674308\n",
              "37  TfidfVectorizer  ...  0.674308\n",
              "13  TfidfVectorizer  ...  0.674271\n",
              "14  TfidfVectorizer  ...  0.674271\n",
              "15  TfidfVectorizer  ...  0.674271\n",
              "32  TfidfVectorizer  ...  0.674197\n",
              "\n",
              "[20 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QYTwyMtWhAZ"
      },
      "source": [
        "## Задание 5.2 Регулярные выражения\n",
        "\n",
        "Регулярные выражения - способ поиска и анализа строк. Например, можно понять, какие даты в наборе строк представлены в формате DD/MM/YYYY, а какие - в других форматах. \n",
        "\n",
        "Или бывает, например, что перед работой с текстом, надо почистить его от своеобразного мусора: упоминаний пользователей, url и так далее.\n",
        "\n",
        "Навык полезный, давайте в нём тоже потренируемся.\n",
        "\n",
        "Для работы с регулярными выражениями есть библиотека **re**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaUW5S4gWhAb"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6aYh7Osl8xr"
      },
      "source": [
        "В регулярных выражениях, кроме привычных символов-букв, есть специальные символы:\n",
        "* **?а** - ноль или один символ **а**\n",
        "* **+а** - один или более символов **а**\n",
        "* **\\*а** - ноль или более символов **а** (не путать с +)\n",
        "* **.** - любое количество любого символа\n",
        "\n",
        "Пример:\n",
        "Выражению \\*a?b. соответствуют последовательности a, ab, abc, aa, aac НО НЕ abb!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7zOFFA3l_KQ"
      },
      "source": [
        "Рассмотрим подробно несколько наиболее полезных функций:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbJrUpARWhAd"
      },
      "source": [
        "### findall\n",
        "возвращает список всех найденных непересекающихся совпадений.\n",
        "\n",
        "Регулярное выражение **ab+c.**: \n",
        "* **a** - просто символ **a**\n",
        "* **b+** - один или более символов **b**\n",
        "* **c** - просто символ **c**\n",
        "* **.** - любой символ\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2athHzKuWhAd",
        "outputId": "18411bca-3b25-429f-e3d5-7fbf89df2ca5"
      },
      "source": [
        "result = re.findall('ab+c.', 'atdsytrcjytabcxabcdavu\\tyjvgkabcdartuyfgabbbcdavbhi8h.ojp;') \n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abcx', 'abcd', 'abcd', 'abbbcd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9FpIw5RWhAf"
      },
      "source": [
        "Вопрос на внимательность: почему нет abcx?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5ttzoxEWhAg"
      },
      "source": [
        "**Задание**: вернуть список первых двух букв каждого слова в строке, состоящей из нескольких слов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZR2AEq3WhAg",
        "outputId": "bfe84769-6dc0-460d-e4f8-c6bf5f99e955"
      },
      "source": [
        "result = re.findall(r'[^-]\\b\\w\\w', 'there is a lot of strangers at night')\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' is', ' lo', ' of', ' st', ' at', ' ni']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI18l-l9WhAk"
      },
      "source": [
        "### split\n",
        "разделяет строку по заданному шаблону\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVKdRoc1WhAl",
        "outputId": "bbc6ddb2-204e-4abf-ff63-85f153533a5a"
      },
      "source": [
        "result = re.split(',', 'itsy, bitsy, teenie, weenie') \n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['itsy', ' bitsy', ' teenie', ' weenie']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10u5efuSWhAm"
      },
      "source": [
        "можно указать максимальное количество разбиений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U9EQZMwWhAn",
        "outputId": "4cd5ee78-13b3-48a0-ac6f-527d044f456d"
      },
      "source": [
        "result = re.split(',', 'itsy, bitsy, teenie, weenie', maxsplit=2) \n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['itsy', ' bitsy', ' teenie, weenie']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EMcMyflWhAp"
      },
      "source": [
        "**Задание**: разбейте строку, состоящую из нескольких предложений, по точкам, но не более чем на 3 предложения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVgPSjEOWhAp",
        "outputId": "4f7bb09c-9cef-4f3b-953c-361c5f7a3548"
      },
      "source": [
        "string = 'Two roads diverged in a yellow wood, and sorry I could not travel both. And be one traveler, long I stood. And looked down one as far as I could to where it bent in the undergrowth.'\n",
        "result = re.split('\\.', string , maxsplit=2) \n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Two roads diverged in a yellow wood, and sorry I could not travel both',\n",
              " ' And be one traveler, long I stood',\n",
              " ' And looked down one as far as I could to where it bent in the undergrowth.']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wrEGqBSWhAr"
      },
      "source": [
        "### sub\n",
        "ищет шаблон в строке и заменяет все совпадения на указанную подстроку\n",
        "\n",
        "параметры: (pattern, repl, string)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az3KxKWwWhAr",
        "outputId": "423f4ba5-7666-472c-9a75-e24115487026"
      },
      "source": [
        "result = re.sub('a', 'b', 'abcabc')\n",
        "print (result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bbcbbc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD0n7_HPWhAt"
      },
      "source": [
        "**Задание**: напишите регулярное выражение, которое позволит заменить все цифры в строке на \"DIG\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s_Sdu7xlWhAu",
        "outputId": "bfd8bd20-c729-49ff-be29-85a72a3a27fe"
      },
      "source": [
        "string = 'I am the 2 in the list, a bird has 2 willows. 123'\n",
        "result = re.sub('[1-9+]', 'DIG', string)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I am the DIG in the list, a bird has DIG willows. DIGDIGDIG'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8__oi1PWhAv"
      },
      "source": [
        "**Задание**: напишите  регулярное выражение, которое позволит убрать url из строки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KwNS9zt4WhAv",
        "outputId": "9e5e70c0-2e49-4bac-fdd5-4228065cfcef"
      },
      "source": [
        "string = 'Is it my vk profile link: https://vk.com/feed'\n",
        "result = re.sub('https://[^\\s]+', '', string)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Is it my vk profile link: '"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gStgBJy2WhAx"
      },
      "source": [
        "### compile\n",
        "компилирует регулярное выражение в отдельный объект"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JstTupisWhAy",
        "outputId": "7a446646-678e-4b80-d192-59926189479c"
      },
      "source": [
        "# Пример: построение списка всех слов строки:\n",
        "prog = re.compile('[А-Яа-яё\\-]+')\n",
        "prog.findall(\"Слова? Да, больше, ещё больше слов! Что-то ещё.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Слова', 'Да', 'больше', 'ещё', 'больше', 'слов', 'Что-то', 'ещё']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXEXc3G0WhA2"
      },
      "source": [
        "**Задание**: для выбранной строки постройте список слов, которые длиннее трех символов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFvnIWbUWhA2",
        "outputId": "a63cb0ef-5a1b-460b-ec9d-80f78d687b9b"
      },
      "source": [
        "prog = re.compile('[А-Яа-яё\\-]{4,}')\n",
        "prog.findall(\"Кружка стоит на столе, шар, лом, мел\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Кружка', 'стоит', 'столе']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQDNZ3HQWhA3"
      },
      "source": [
        "**Задание**: вернуть список доменов (@gmail.com) из списка адресов электронной почты:\n",
        "\n",
        "```\n",
        "abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nJ4U4gJJvEO",
        "outputId": "9abc9193-4899-41e5-81ce-9a295a169e49"
      },
      "source": [
        "prog = re.compile('.+@gmail.com')\n",
        "prog.findall('abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abc.test@gmail.com']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}